{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Extração de Características da Música e Pré-processamento (Português e Inglês)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jorge/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jorge/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /home/jorge/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Dependências\n",
    "import string\n",
    "import os\n",
    "import textlytics\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from collections import Counter\n",
    "from collections import OrderedDict #Ordena alfabeticamente\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nltk.download('stopwords')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "textlytics.config.setLanguage('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura do dataset\n",
    "def read_data(path, sep):\n",
    "    data = pd.read_csv(path, sep=sep)\n",
    "    data = data.loc[:, ~data.columns.str.contains('^Unnamed')]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data('music_mar_2021/data/raw/pop_mar21.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>genero</th>\n",
       "      <th>exib</th>\n",
       "      <th>titulo</th>\n",
       "      <th>artista</th>\n",
       "      <th>letras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>Tecnopop</td>\n",
       "      <td>936</td>\n",
       "      <td>Sick Sad World</td>\n",
       "      <td>Blood On The Dance Floor</td>\n",
       "      <td>The poor.The broken.The abused.And it's spoken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>Tecnopop</td>\n",
       "      <td>24437</td>\n",
       "      <td>Sexting</td>\n",
       "      <td>Blood On The Dance Floor</td>\n",
       "      <td>Less than three.Is just a tease.Send those noo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>Tecnopop</td>\n",
       "      <td>5726</td>\n",
       "      <td>Call Me Master</td>\n",
       "      <td>Blood On The Dance Floor</td>\n",
       "      <td>Tonight our bodies getting intertwined.It's fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>Tecnopop</td>\n",
       "      <td>2151</td>\n",
       "      <td>Success Is The Best Revenge</td>\n",
       "      <td>Blood On The Dance Floor</td>\n",
       "      <td>I'm a killer.A chiller.A bonafied thriller.Ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>Tecnopop</td>\n",
       "      <td>24252</td>\n",
       "      <td>Bewitched</td>\n",
       "      <td>Blood On The Dance Floor</td>\n",
       "      <td>You're attractive little witch you're beautifu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang    genero   exib                       titulo  \\\n",
       "0   en  Tecnopop    936               Sick Sad World   \n",
       "1   en  Tecnopop  24437                      Sexting   \n",
       "2   en  Tecnopop   5726               Call Me Master   \n",
       "3   en  Tecnopop   2151  Success Is The Best Revenge   \n",
       "4   en  Tecnopop  24252                    Bewitched   \n",
       "\n",
       "                    artista                                             letras  \n",
       "0  Blood On The Dance Floor  The poor.The broken.The abused.And it's spoken...  \n",
       "1  Blood On The Dance Floor  Less than three.Is just a tease.Send those noo...  \n",
       "2  Blood On The Dance Floor  Tonight our bodies getting intertwined.It's fu...  \n",
       "3  Blood On The Dance Floor  I'm a killer.A chiller.A bonafied thriller.Ope...  \n",
       "4  Blood On The Dance Floor  You're attractive little witch you're beautifu...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para recuperar as classes\n",
    "def classesRetrieval(dataframe,labels):\n",
    "    df = dataframe\n",
    "    df['label'] = labels\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoderLabel(data,labelfield):\n",
    "    def encoder(label,labels_dict):\n",
    "        return labels_dict[label]\n",
    "    \n",
    "    qtdLabels = len(set(data[labelfield]))\n",
    "    nameLabels = set(data[labelfield])\n",
    "    labels_dict = {}\n",
    "    i = 0\n",
    "    for l in nameLabels:\n",
    "        labels_dict[l] = i\n",
    "        i = i + 1\n",
    "    print(\"As classes foram codificadas da seguinte forma:\")\n",
    "    print(labels_dict)\n",
    "    print()\n",
    "    return data[labelfield].apply(encoder, labels_dict=labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preserva as classes em uma variavel\n",
    "genero = data['genero']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de instâncias: 8836\n",
      "Gênero Tecnopop: 2169\n",
      "Gênero Power-Pop: 1162\n",
      "Gênero Pop Rock: 5505\n"
     ]
    }
   ],
   "source": [
    "print(\"Total de instâncias: {}\".format(len(data)))\n",
    "\n",
    "for gen in data.genero.unique():\n",
    "    print(\"Gênero {}: {}\".format(gen,len(data[data.genero == gen ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The poor.The broken.The abused.And it's spoken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Less than three.Is just a tease.Send those noo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tonight our bodies getting intertwined.It's fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm a killer.A chiller.A bonafied thriller.Ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You're attractive little witch you're beautifu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              letras\n",
       "0  The poor.The broken.The abused.And it's spoken...\n",
       "1  Less than three.Is just a tease.Send those noo...\n",
       "2  Tonight our bodies getting intertwined.It's fu...\n",
       "3  I'm a killer.A chiller.A bonafied thriller.Ope...\n",
       "4  You're attractive little witch you're beautifu..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns=['lang', 'genero','exib','titulo','artista'])\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extração de Características Estatísticas Textuais (CET) e Part of Speech Tagging (POS Tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Torna o texto em letras minúsculas\n",
    "def lowercase(text):\n",
    "    text = str(text).lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove algumas impurezas da coleção textual\n",
    "def fix_words(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'\\bh[ah]*\\b', \"\", text) # remove \"hahahah\" \n",
    "    text = re.sub(r'\\b[oh]*\\b', \"\", text) # remove \"oohhhh\" \n",
    "    #text = re.sub(r'\\bq[ue]*\\b', \"que\", text) # normaliza \"queeeeeeeeee\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove ruídos simples que podem interferir na contagem e extração das características estatísticas\n",
    "def simpleNoiseRemoval(text):\n",
    "    text = re.sub(r\"[0-9]+\", \"\", text)\n",
    "    text = text.replace(\"#\",\"\")\n",
    "    text = text.replace(\"(\",\"\")\n",
    "    text = text.replace(\")\",\"\")\n",
    "    text = text.replace(\"...\",\"\")\n",
    "    text = text.replace(\"!\",\"\")\n",
    "    text = text.replace(\"&\",\"\")\n",
    "    text = text.replace(\"&amp\",\"\")\n",
    "    text = text.replace(\"'\",\"\")\n",
    "    text = text.replace('\"','')\n",
    "    text = text.replace('‘','')\n",
    "    \n",
    "    text = text.replace('é','')\n",
    "    text = text.replace('','')\n",
    "    text = text.replace('aa','')\n",
    "    text = text.replace('–','')\n",
    "    text = text.replace('’','')\n",
    "    text = text.replace('em','')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['letras'] =  data['letras'].apply(lowercase)\n",
    "data['letras'] =  data['letras'].apply(fix_words)\n",
    "data['letras'] =  data['letras'].apply(simpleNoiseRemoval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the poor.the broken.the abused.and its spoken....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>less than three.is just a tease.send those noo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tonight our bodies getting intertwined.its fuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im a killer.a chiller.a bonafied thriller.open...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>youre attractive little witch youre beautiful....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              letras\n",
       "0  the poor.the broken.the abused.and its spoken....\n",
       "1  less than three.is just a tease.send those noo...\n",
       "2  tonight our bodies getting intertwined.its fuc...\n",
       "3  im a killer.a chiller.a bonafied thriller.open...\n",
       "4  youre attractive little witch youre beautiful...."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "textlytics.features2Dataframe(data,'letras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letras</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Words</th>\n",
       "      <th>AvgWordLen</th>\n",
       "      <th>UniqueWords</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>AvgWordsSentence</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>AvgSyllableWords</th>\n",
       "      <th>RareWordsRatio</th>\n",
       "      <th>LexicalDiversity</th>\n",
       "      <th>Readability</th>\n",
       "      <th>ReadabilitySchoolarity</th>\n",
       "      <th>IncidenceVerbs</th>\n",
       "      <th>IncidenceAdj</th>\n",
       "      <th>IncidenceNouns</th>\n",
       "      <th>IncidenceCon</th>\n",
       "      <th>IncidencePron</th>\n",
       "      <th>ContentIncidence</th>\n",
       "      <th>ContentDiversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the poor.the broken.the abused.and its spoken....</td>\n",
       "      <td>1073</td>\n",
       "      <td>213</td>\n",
       "      <td>4.126761</td>\n",
       "      <td>119</td>\n",
       "      <td>32</td>\n",
       "      <td>6.656250</td>\n",
       "      <td>249</td>\n",
       "      <td>1.169014</td>\n",
       "      <td>0.427230</td>\n",
       "      <td>0.558685</td>\n",
       "      <td>101.180315</td>\n",
       "      <td>5th grade</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>less than three.is just a tease.send those noo...</td>\n",
       "      <td>1611</td>\n",
       "      <td>354</td>\n",
       "      <td>3.627119</td>\n",
       "      <td>173</td>\n",
       "      <td>73</td>\n",
       "      <td>4.849315</td>\n",
       "      <td>386</td>\n",
       "      <td>1.090395</td>\n",
       "      <td>0.316384</td>\n",
       "      <td>0.488701</td>\n",
       "      <td>109.665488</td>\n",
       "      <td>5th grade</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.528249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tonight our bodies getting intertwined.its fuc...</td>\n",
       "      <td>1758</td>\n",
       "      <td>372</td>\n",
       "      <td>3.887097</td>\n",
       "      <td>131</td>\n",
       "      <td>60</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>439</td>\n",
       "      <td>1.180108</td>\n",
       "      <td>0.131720</td>\n",
       "      <td>0.352151</td>\n",
       "      <td>100.704903</td>\n",
       "      <td>5th grade</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.505376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im a killer.a chiller.a bonafied thriller.open...</td>\n",
       "      <td>1190</td>\n",
       "      <td>258</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>150</td>\n",
       "      <td>72</td>\n",
       "      <td>3.583333</td>\n",
       "      <td>285</td>\n",
       "      <td>1.104651</td>\n",
       "      <td>0.437984</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>109.744428</td>\n",
       "      <td>5th grade</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.449612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>youre attractive little witch youre beautiful....</td>\n",
       "      <td>1502</td>\n",
       "      <td>332</td>\n",
       "      <td>3.575301</td>\n",
       "      <td>81</td>\n",
       "      <td>39</td>\n",
       "      <td>8.512821</td>\n",
       "      <td>362</td>\n",
       "      <td>1.090361</td>\n",
       "      <td>0.078313</td>\n",
       "      <td>0.243976</td>\n",
       "      <td>105.949909</td>\n",
       "      <td>5th grade</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.548193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              letras  Characters  Words  \\\n",
       "0  the poor.the broken.the abused.and its spoken....        1073    213   \n",
       "1  less than three.is just a tease.send those noo...        1611    354   \n",
       "2  tonight our bodies getting intertwined.its fuc...        1758    372   \n",
       "3  im a killer.a chiller.a bonafied thriller.open...        1190    258   \n",
       "4  youre attractive little witch youre beautiful....        1502    332   \n",
       "\n",
       "   AvgWordLen  UniqueWords  Sentences  AvgWordsSentence  Syllables  \\\n",
       "0    4.126761          119         32          6.656250        249   \n",
       "1    3.627119          173         73          4.849315        386   \n",
       "2    3.887097          131         60          6.200000        439   \n",
       "3    3.833333          150         72          3.583333        285   \n",
       "4    3.575301           81         39          8.512821        362   \n",
       "\n",
       "   AvgSyllableWords  RareWordsRatio  LexicalDiversity  Readability  \\\n",
       "0          1.169014        0.427230          0.558685   101.180315   \n",
       "1          1.090395        0.316384          0.488701   109.665488   \n",
       "2          1.180108        0.131720          0.352151   100.704903   \n",
       "3          1.104651        0.437984          0.581395   109.744428   \n",
       "4          1.090361        0.078313          0.243976   105.949909   \n",
       "\n",
       "  ReadabilitySchoolarity  IncidenceVerbs  IncidenceAdj  IncidenceNouns  \\\n",
       "0              5th grade           0.041         0.033           0.055   \n",
       "1              5th grade           0.081         0.030           0.076   \n",
       "2              5th grade           0.079         0.043           0.066   \n",
       "3              5th grade           0.051         0.017           0.048   \n",
       "4              5th grade           0.072         0.011           0.099   \n",
       "\n",
       "   IncidenceCon  IncidencePron  ContentIncidence  ContentDiversity  \n",
       "0         0.038          0.007             0.129          0.605634  \n",
       "1         0.041          0.047             0.187          0.528249  \n",
       "2         0.049          0.060             0.188          0.505376  \n",
       "3         0.033          0.032             0.116          0.449612  \n",
       "4         0.061          0.029             0.182          0.548193  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['Readability','ReadabilitySchoolarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista com o nome dos atributos (colunas) da representação CET\n",
    "cet_att = list(data)[1:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_att = list(data)[11:18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extração da representação Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "    \n",
    "# Remove as stopwords de um texto\n",
    "def remove_stop_words(text, stopwords):\n",
    "    for sw in stopwords:\n",
    "        text = re.sub(r'\\b%s\\b' % sw, \"\", text)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):  \n",
    "    # re.sub(replace_expression, replace_string, target)\n",
    "    new_text = re.sub(r\"\\.|,|;|:|-|!|\\?|´|`|^|'\", \" \", text)\n",
    "    new_text = new_text.strip()\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_others(text):\n",
    "    noise = ['\"','(',')','[',']','{','}',\"'\",'%','*','“','“’','#','?','@',\"/\",'\\\\',\"_\",'&','amp','.','+','$','※','=','=','^','”']\n",
    "    \n",
    "    for n in noise:\n",
    "        new_text = text.replace(n,\"\")\n",
    "    \n",
    "    new_text = re.sub(r\"u+h\",\"\", new_text)\n",
    "    new_text = re.sub(r\"o+h\",\"\", new_text)\n",
    "    new_text = re.sub(r\"a+h\",\"\", new_text)\n",
    "    new_text = re.sub(r\"ah+\",\"\", new_text)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(text):\n",
    "    text = str(text)\n",
    "    new_text = re.sub(r\"[0-9]+\", \"\", text)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria um dicionário dos radicais para as palavras mais frequentes\n",
    "def generate_retrieval_dict(dataset,fieldName):\n",
    "    collection = \" \".join(dataset[fieldName])\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    #stemmer = RSLPStemmer()\n",
    "    word_list = collection.split()\n",
    "    root = []\n",
    "    result = []\n",
    "    retrieval_dict = {}\n",
    "    for w in word_list:\n",
    "        word_old = w\n",
    "        word_new = stemmer.stem(w)\n",
    "        result.append(word_new)\n",
    "        if (len(word_new)<len(word_old)):\n",
    "            root.append(word_new)\n",
    "    root = [w for w in set(root)]\n",
    "    if(len(root)>0):\n",
    "        for r in root:\n",
    "            retrieval = []\n",
    "            for w in word_list:\n",
    "                if(r in w):\n",
    "                    retrieval.append(w)\n",
    "            counts = dict(Counter(retrieval).most_common(1))\n",
    "            labels, values = zip(*counts.items())\n",
    "            meaningful = str(labels[0])\n",
    "            retrieval_dict[r] = meaningful\n",
    "    return retrieval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming function\n",
    "def stemming(text):\n",
    "    # Instance the Snowball stemmer\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    #stemmer = RSLPStemmer()\n",
    "    word_list = text.split()\n",
    "    result = []\n",
    "    for w in word_list:\n",
    "        result.append(stemmer.stem(w))\n",
    "    result = \" \".join(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lengthening pattern to match on text\n",
    "\n",
    "lengthening_pattern = \"a{3,}|b{3,}|c{3,}|d{3,}|e{3,}|f{3,}|g{3,}|h{3,}|i{3,}|j{3,}|\" \\\n",
    "\"k{3,}|l{3,}|m{3,}|n{3,}|o{3,}|p{3,}|q{3,}|r{3,}|s{3,}|t{3,}|\" \\\n",
    "\"u{3,}|v{3,}|x{3,}|w{3,}|y{3,}|z{3,}\"\n",
    "\n",
    "# Reduce lengthening in a text\n",
    "def lengthening_reduction(text, lenPattern):\n",
    "    lengthenings = re.findall(lenPattern, text)\n",
    "    if lengthenings:\n",
    "        lengthenings = lengthenings[0]\n",
    "        text = re.sub(lengthenings, lengthenings[0:1], text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lengthening_reduction_multiple(text, lenPattern):\n",
    "    lengthenings = re.findall(lenPattern, text)\n",
    "    for lengthening in lengthenings:\n",
    "        text = re.sub(lengthening, lengthening[0:1], text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "# The argument \"special_terms\" refers to terms that should not be parsed.\n",
    "\n",
    "def lemmatizing(text, special_terms=[]):\n",
    "    \n",
    "    tokens = textlytics.word_tokenize(text)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = []\n",
    "    \n",
    "    for token, tag in tags:\n",
    "        if token in special_terms:\n",
    "            lemmatized_tokens.append(token)\n",
    "        else:\n",
    "            lemma = lemmatizer.lemmatize(token, pos=get_wordnet_pos(tag))\n",
    "            lemmatized_tokens.append(lemma)\n",
    "        \n",
    "    lemmatized_tokens_string = \" \".join([token for token in lemmatized_tokens])\n",
    "    \n",
    "    return lemmatized_tokens_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Troca as palavras radicalizadas pela melhor representação\n",
    "def stemming_retrieval(text,dic):\n",
    "    p = 0\n",
    "    result = text.split()\n",
    "    while p < len(result):\n",
    "        if(result[p] in dic):\n",
    "            key = result[p]\n",
    "            result[p] = dic[key]\n",
    "        p+=1\n",
    "    result = \" \".join(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_ascii_letters(text):    \n",
    "    letters = set(string.ascii_letters)\n",
    "    tokens = textlytics.word_tokenize(text)\n",
    "    new_tokens = []\n",
    "\n",
    "    for token in tokens:\n",
    "        word = ''.join((filter(lambda x: x in letters, token)))\n",
    "        if(len(word)>=3):\n",
    "            new_tokens.append(word)\n",
    "\n",
    "    new_text = ' '.join(new_tokens)\n",
    "    \n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(dataframe, fieldName, config):   \n",
    "    if config[\"lowercase\"] == True:\n",
    "        dataframe[fieldName] = dataframe[fieldName].apply(lowercase)\n",
    "        \n",
    "    if config[\"remove_numbers\"] == True:\n",
    "        dataframe[fieldName] = dataframe[fieldName].apply(remove_numbers)\n",
    "    \n",
    "    if config[\"remove_stopwords\"] == True:\n",
    "        dataframe[fieldName] = dataframe[fieldName].apply(remove_stop_words, stopwords=stopwords)\n",
    "        \n",
    "    if config[\"generate_retrieval_dict\"] == True:\n",
    "        retrieval_dict = generate_retrieval_dict(dataframe,fieldName)\n",
    "        \n",
    "    if config[\"stemming\"] == True:\n",
    "        dataframe[fieldName] = dataframe[fieldName].apply(stemming)\n",
    "\n",
    "    if config[\"stemming_retrieval\"] == True:\n",
    "        dataframe[fieldName] = dataframe[fieldName].apply(stemming_retrieval, dic=retrieval_dict)\n",
    "        \n",
    "    if config[\"lemmatizing\"] == True:\n",
    "        dataframe[fieldName] = dataframe[fieldName].apply(lemmatizing)\n",
    "        \n",
    "    if config[\"reduce_lengthening\"] == True:\n",
    "        dataframe[fieldName] = dataframe[fieldName].apply(lengthening_reduction_multiple, lenPattern=lengthening_pattern)\n",
    "        \n",
    "    if config[\"remove_others\"] == True:\n",
    "        dataframe[fieldName] = dataframe[fieldName].apply(remove_others)\n",
    "        \n",
    "    if config[\"remove_punctuation\"] == True:\n",
    "        dataframe[fieldName] = dataframe[fieldName].apply(remove_punctuation)\n",
    "        \n",
    "    if config[\"only_ascii_letters\"] == True:\n",
    "        dataframe[fieldName] = dataframe[fieldName].apply(only_ascii_letters)\n",
    "        \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {  \"lowercase\": True, \\\n",
    "            \"remove_punctuation\": True, \\\n",
    "          \"remove_others\": True, \\\n",
    "            \"remove_numbers\": True, \\\n",
    "            \"remove_stopwords\": True,\n",
    "         \"generate_retrieval_dict\": False,\n",
    "         \"stemming\":True,\n",
    "          \"lemmatizing\":True,\n",
    "          \"reduce_lengthening\":False,\n",
    "         \"stemming_retrieval\":False,\n",
    "         \"only_ascii_letters\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    the poor.the broken.the abused.and its spoken....\n",
      "1    less than three.is just a tease.send those noo...\n",
      "2    tonight our bodies getting intertwined.its fuc...\n",
      "3    im a killer.a chiller.a bonafied thriller.open...\n",
      "4    youre attractive little witch youre beautiful....\n",
      "Name: letras, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data[\"letras\"].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    poor broken abuse spoken american dream turn n...\n",
      "1    less three tease send noodz mak drool hit make...\n",
      "2    tonight bodi get intertwine fuck filthi fee bl...\n",
      "3    killer chiller bonafi thriller open like bottl...\n",
      "4    your attract littl witch your beautiful wicked...\n",
      "Name: letras, dtype: object\n"
     ]
    }
   ],
   "source": [
    "preprocessing(data, 'letras', config)\n",
    "print(data[\"letras\"].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformData(data, fieldName, my_tokenizer, weight):\n",
    "    \n",
    "    if weight == \"TP\":\n",
    "        vectorizer = CountVectorizer(tokenizer=my_tokenizer, binary=True)\n",
    "        X = vectorizer.fit_transform(data[fieldName])\n",
    "    \n",
    "    elif weight == \"TF\":\n",
    "        vectorizer = CountVectorizer(tokenizer=my_tokenizer)\n",
    "        X = vectorizer.fit_transform(data[fieldName])\n",
    "        \n",
    "    elif weight == \"TFIDF\":\n",
    "        vectorizer = TfidfVectorizer(tokenizer=my_tokenizer)\n",
    "        X = vectorizer.fit_transform(data[fieldName])\n",
    "        \n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    text_collection = OrderedDict([(index, text) for index, text in enumerate(data[fieldName])])\n",
    "    corpus_index = [n for n in text_collection]\n",
    "    df = pd.DataFrame(X.todense(), index=corpus_index, columns=feature_names)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textlytics import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "BowTFIDF = transformData(data,'letras',word_tokenize,'TFIDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aba</th>\n",
       "      <th>aback</th>\n",
       "      <th>abacus</th>\n",
       "      <th>abad</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abate</th>\n",
       "      <th>abattoir</th>\n",
       "      <th>abba</th>\n",
       "      <th>...</th>\n",
       "      <th>zooropavosprung</th>\n",
       "      <th>zooropayou</th>\n",
       "      <th>zoovier</th>\n",
       "      <th>zorn</th>\n",
       "      <th>zsa</th>\n",
       "      <th>zucchero</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zuma</th>\n",
       "      <th>zwei</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24900 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aba  aback  abacus  abad  abandon  abandoned  abandonment  abate  abattoir  \\\n",
       "0  0.0    0.0     0.0   0.0      0.0        0.0          0.0    0.0       0.0   \n",
       "1  0.0    0.0     0.0   0.0      0.0        0.0          0.0    0.0       0.0   \n",
       "2  0.0    0.0     0.0   0.0      0.0        0.0          0.0    0.0       0.0   \n",
       "3  0.0    0.0     0.0   0.0      0.0        0.0          0.0    0.0       0.0   \n",
       "4  0.0    0.0     0.0   0.0      0.0        0.0          0.0    0.0       0.0   \n",
       "\n",
       "   abba  ...  zooropavosprung  zooropayou  zoovier  zorn  zsa  zucchero  \\\n",
       "0   0.0  ...              0.0         0.0      0.0   0.0  0.0       0.0   \n",
       "1   0.0  ...              0.0         0.0      0.0   0.0  0.0       0.0   \n",
       "2   0.0  ...              0.0         0.0      0.0   0.0  0.0       0.0   \n",
       "3   0.0  ...              0.0         0.0      0.0   0.0  0.0       0.0   \n",
       "4   0.0  ...              0.0         0.0      0.0   0.0  0.0       0.0   \n",
       "\n",
       "   zucchini  zulu  zuma  zwei  \n",
       "0       0.0   0.0   0.0   0.0  \n",
       "1       0.0   0.0   0.0   0.0  \n",
       "2       0.0   0.0   0.0   0.0  \n",
       "3       0.0   0.0   0.0   0.0  \n",
       "4       0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 24900 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BowTFIDF.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection (for BoW only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "X= BowTFIDF\n",
    "\n",
    "labels ={}\n",
    "i = 0\n",
    "\n",
    "for label in set(genero):\n",
    "    labels[label] = i\n",
    "    i+=1\n",
    "\n",
    "y = [labels[l] for l in genero]\n",
    "\n",
    "selector = SelectPercentile(percentile=20).fit(X,y)\n",
    "\n",
    "#selector = SelectFromModel(estimator=LogisticRegression()).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_index = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = BowTFIDF.columns[col_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "BowTFIDF = BowTFIDF[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aba</th>\n",
       "      <th>abc</th>\n",
       "      <th>aberdeen</th>\n",
       "      <th>abide</th>\n",
       "      <th>abil</th>\n",
       "      <th>ability</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abolish</th>\n",
       "      <th>abridge</th>\n",
       "      <th>absenc</th>\n",
       "      <th>...</th>\n",
       "      <th>zanzibar</th>\n",
       "      <th>zebedee</th>\n",
       "      <th>zee</th>\n",
       "      <th>zest</th>\n",
       "      <th>zig</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoomin</th>\n",
       "      <th>zorn</th>\n",
       "      <th>zulu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4980 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aba  abc  aberdeen  abide  abil  ability  aboard  abolish  abridge  absenc  \\\n",
       "0  0.0  0.0       0.0    0.0   0.0      0.0     0.0      0.0      0.0     0.0   \n",
       "1  0.0  0.0       0.0    0.0   0.0      0.0     0.0      0.0      0.0     0.0   \n",
       "2  0.0  0.0       0.0    0.0   0.0      0.0     0.0      0.0      0.0     0.0   \n",
       "3  0.0  0.0       0.0    0.0   0.0      0.0     0.0      0.0      0.0     0.0   \n",
       "4  0.0  0.0       0.0    0.0   0.0      0.0     0.0      0.0      0.0     0.0   \n",
       "\n",
       "   ...  zanzibar  zebedee  zee  zest  zig  zillion  zoom  zoomin  zorn  zulu  \n",
       "0  ...       0.0      0.0  0.0   0.0  0.0      0.0   0.0     0.0   0.0   0.0  \n",
       "1  ...       0.0      0.0  0.0   0.0  0.0      0.0   0.0     0.0   0.0   0.0  \n",
       "2  ...       0.0      0.0  0.0   0.0  0.0      0.0   0.0     0.0   0.0   0.0  \n",
       "3  ...       0.0      0.0  0.0   0.0  0.0      0.0   0.0     0.0   0.0   0.0  \n",
       "4  ...       0.0      0.0  0.0   0.0  0.0      0.0   0.0     0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 4980 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BowTFIDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Devolvendo as classes para cada representação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cet = classesRetrieval(data[cet_att],genero)\n",
    "\n",
    "pos = classesRetrieval(data[pos_att],genero)\n",
    "\n",
    "bow = classesRetrieval(BowTFIDF,genero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Characters</th>\n",
       "      <th>Words</th>\n",
       "      <th>AvgWordLen</th>\n",
       "      <th>UniqueWords</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>AvgWordsSentence</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>AvgSyllableWords</th>\n",
       "      <th>RareWordsRatio</th>\n",
       "      <th>LexicalDiversity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1073</td>\n",
       "      <td>213</td>\n",
       "      <td>4.126761</td>\n",
       "      <td>119</td>\n",
       "      <td>32</td>\n",
       "      <td>6.656250</td>\n",
       "      <td>249</td>\n",
       "      <td>1.169014</td>\n",
       "      <td>0.427230</td>\n",
       "      <td>0.558685</td>\n",
       "      <td>Tecnopop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1611</td>\n",
       "      <td>354</td>\n",
       "      <td>3.627119</td>\n",
       "      <td>173</td>\n",
       "      <td>73</td>\n",
       "      <td>4.849315</td>\n",
       "      <td>386</td>\n",
       "      <td>1.090395</td>\n",
       "      <td>0.316384</td>\n",
       "      <td>0.488701</td>\n",
       "      <td>Tecnopop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1758</td>\n",
       "      <td>372</td>\n",
       "      <td>3.887097</td>\n",
       "      <td>131</td>\n",
       "      <td>60</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>439</td>\n",
       "      <td>1.180108</td>\n",
       "      <td>0.131720</td>\n",
       "      <td>0.352151</td>\n",
       "      <td>Tecnopop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1190</td>\n",
       "      <td>258</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>150</td>\n",
       "      <td>72</td>\n",
       "      <td>3.583333</td>\n",
       "      <td>285</td>\n",
       "      <td>1.104651</td>\n",
       "      <td>0.437984</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>Tecnopop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1502</td>\n",
       "      <td>332</td>\n",
       "      <td>3.575301</td>\n",
       "      <td>81</td>\n",
       "      <td>39</td>\n",
       "      <td>8.512821</td>\n",
       "      <td>362</td>\n",
       "      <td>1.090361</td>\n",
       "      <td>0.078313</td>\n",
       "      <td>0.243976</td>\n",
       "      <td>Tecnopop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Characters  Words  AvgWordLen  UniqueWords  Sentences  AvgWordsSentence  \\\n",
       "0        1073    213    4.126761          119         32          6.656250   \n",
       "1        1611    354    3.627119          173         73          4.849315   \n",
       "2        1758    372    3.887097          131         60          6.200000   \n",
       "3        1190    258    3.833333          150         72          3.583333   \n",
       "4        1502    332    3.575301           81         39          8.512821   \n",
       "\n",
       "   Syllables  AvgSyllableWords  RareWordsRatio  LexicalDiversity     label  \n",
       "0        249          1.169014        0.427230          0.558685  Tecnopop  \n",
       "1        386          1.090395        0.316384          0.488701  Tecnopop  \n",
       "2        439          1.180108        0.131720          0.352151  Tecnopop  \n",
       "3        285          1.104651        0.437984          0.581395  Tecnopop  \n",
       "4        362          1.090361        0.078313          0.243976  Tecnopop  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IncidenceVerbs</th>\n",
       "      <th>IncidenceAdj</th>\n",
       "      <th>IncidenceNouns</th>\n",
       "      <th>IncidenceCon</th>\n",
       "      <th>IncidencePron</th>\n",
       "      <th>ContentIncidence</th>\n",
       "      <th>ContentDiversity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.605634</td>\n",
       "      <td>Tecnopop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.081</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.528249</td>\n",
       "      <td>Tecnopop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.079</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.505376</td>\n",
       "      <td>Tecnopop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.051</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.449612</td>\n",
       "      <td>Tecnopop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.072</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.548193</td>\n",
       "      <td>Tecnopop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IncidenceVerbs  IncidenceAdj  IncidenceNouns  IncidenceCon  IncidencePron  \\\n",
       "0           0.041         0.033           0.055         0.038          0.007   \n",
       "1           0.081         0.030           0.076         0.041          0.047   \n",
       "2           0.079         0.043           0.066         0.049          0.060   \n",
       "3           0.051         0.017           0.048         0.033          0.032   \n",
       "4           0.072         0.011           0.099         0.061          0.029   \n",
       "\n",
       "   ContentIncidence  ContentDiversity     label  \n",
       "0             0.129          0.605634  Tecnopop  \n",
       "1             0.187          0.528249  Tecnopop  \n",
       "2             0.188          0.505376  Tecnopop  \n",
       "3             0.116          0.449612  Tecnopop  \n",
       "4             0.182          0.548193  Tecnopop  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aba</th>\n",
       "      <th>abc</th>\n",
       "      <th>aberdeen</th>\n",
       "      <th>abide</th>\n",
       "      <th>abil</th>\n",
       "      <th>ability</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abolish</th>\n",
       "      <th>abridge</th>\n",
       "      <th>absenc</th>\n",
       "      <th>...</th>\n",
       "      <th>zebedee</th>\n",
       "      <th>zee</th>\n",
       "      <th>zest</th>\n",
       "      <th>zig</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoomin</th>\n",
       "      <th>zorn</th>\n",
       "      <th>zulu</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tecnopop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tecnopop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tecnopop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tecnopop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tecnopop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4981 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aba  abc  aberdeen  abide  abil  ability  aboard  abolish  abridge  absenc  \\\n",
       "0  0.0  0.0       0.0    0.0   0.0      0.0     0.0      0.0      0.0     0.0   \n",
       "1  0.0  0.0       0.0    0.0   0.0      0.0     0.0      0.0      0.0     0.0   \n",
       "2  0.0  0.0       0.0    0.0   0.0      0.0     0.0      0.0      0.0     0.0   \n",
       "3  0.0  0.0       0.0    0.0   0.0      0.0     0.0      0.0      0.0     0.0   \n",
       "4  0.0  0.0       0.0    0.0   0.0      0.0     0.0      0.0      0.0     0.0   \n",
       "\n",
       "   ...  zebedee  zee  zest  zig  zillion  zoom  zoomin  zorn  zulu     label  \n",
       "0  ...      0.0  0.0   0.0  0.0      0.0   0.0     0.0   0.0   0.0  Tecnopop  \n",
       "1  ...      0.0  0.0   0.0  0.0      0.0   0.0     0.0   0.0   0.0  Tecnopop  \n",
       "2  ...      0.0  0.0   0.0  0.0      0.0   0.0     0.0   0.0   0.0  Tecnopop  \n",
       "3  ...      0.0  0.0   0.0  0.0      0.0   0.0     0.0   0.0   0.0  Tecnopop  \n",
       "4  ...      0.0  0.0   0.0  0.0      0.0   0.0     0.0   0.0   0.0  Tecnopop  \n",
       "\n",
       "[5 rows x 4981 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportando todas a representações geradas (CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_csv(dataframe,filename):\n",
    "    dataframe.to_csv(filename, index=False)\n",
    "    print(\"Exportado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportado.\n"
     ]
    }
   ],
   "source": [
    "export_to_csv(pos,'music_mar_2021/data/traditional_rep/pop_mar21_pos.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
