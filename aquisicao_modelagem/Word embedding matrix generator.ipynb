{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03- Gerar próprias embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLTK\n",
    "from nltk.stem import RSLPStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('rslp')\n",
    "stemmer_pt = RSLPStemmer()\n",
    "stemmer_en = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#Python\n",
    "import string\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "#Other libraries\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import scipy\n",
    "import joblib\n",
    "from abc import ABCMeta, abstractmethod\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the stopwords\n",
    "stopwords_pt = set(stopwords.words('portuguese'))\n",
    "stopwords_en = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "data = pd.read_csv('data/raw/rock_mar21.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>genero</th>\n",
       "      <th>exib</th>\n",
       "      <th>titulo</th>\n",
       "      <th>artista</th>\n",
       "      <th>letras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>Heavy Metal</td>\n",
       "      <td>132631</td>\n",
       "      <td>Black Diamond</td>\n",
       "      <td>Stratovarius</td>\n",
       "      <td>Again I see you standing there watching me.You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>Heavy Metal</td>\n",
       "      <td>118508</td>\n",
       "      <td>Hunting High And Low</td>\n",
       "      <td>Stratovarius</td>\n",
       "      <td>I feel the wind in my hair.And it's whispering...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>Heavy Metal</td>\n",
       "      <td>76327</td>\n",
       "      <td>Destiny</td>\n",
       "      <td>Stratovarius</td>\n",
       "      <td>The times are changing so fast.I wonder how lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>Heavy Metal</td>\n",
       "      <td>25696</td>\n",
       "      <td>Unbreakable</td>\n",
       "      <td>Stratovarius</td>\n",
       "      <td>Worthless without time.We follow how it flies ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>Heavy Metal</td>\n",
       "      <td>46118</td>\n",
       "      <td>Eagleheart</td>\n",
       "      <td>Stratovarius</td>\n",
       "      <td>All through the night he is lying awake.Wond'r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13018</th>\n",
       "      <td>en</td>\n",
       "      <td>Soft Rock</td>\n",
       "      <td>13882</td>\n",
       "      <td>Graceland</td>\n",
       "      <td>Paul Simon</td>\n",
       "      <td>The Mississippi delta.Was shining like a natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13019</th>\n",
       "      <td>en</td>\n",
       "      <td>Soft Rock</td>\n",
       "      <td>1456</td>\n",
       "      <td>Cool Papa Bell</td>\n",
       "      <td>Paul Simon</td>\n",
       "      <td>It turns out to be.A great thing for me.I don'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13020</th>\n",
       "      <td>en</td>\n",
       "      <td>Soft Rock</td>\n",
       "      <td>14645</td>\n",
       "      <td>The Obvious Child</td>\n",
       "      <td>Paul Simon</td>\n",
       "      <td>Well I'm accustomed to a smooth ride.Or maybe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13021</th>\n",
       "      <td>en</td>\n",
       "      <td>Soft Rock</td>\n",
       "      <td>10755</td>\n",
       "      <td>The Boxer</td>\n",
       "      <td>Paul Simon</td>\n",
       "      <td>I am just a poor boy though my story's seldom ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13022</th>\n",
       "      <td>en</td>\n",
       "      <td>Soft Rock</td>\n",
       "      <td>5624</td>\n",
       "      <td>Me And Julio Down By The Schoolyard</td>\n",
       "      <td>Paul Simon</td>\n",
       "      <td>The mama pajama rolled out of bed.And she ran ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13023 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lang       genero    exib                               titulo  \\\n",
       "0       en  Heavy Metal  132631                        Black Diamond   \n",
       "1       en  Heavy Metal  118508                 Hunting High And Low   \n",
       "2       en  Heavy Metal   76327                              Destiny   \n",
       "3       en  Heavy Metal   25696                          Unbreakable   \n",
       "4       en  Heavy Metal   46118                           Eagleheart   \n",
       "...    ...          ...     ...                                  ...   \n",
       "13018   en    Soft Rock   13882                            Graceland   \n",
       "13019   en    Soft Rock    1456                       Cool Papa Bell   \n",
       "13020   en    Soft Rock   14645                    The Obvious Child   \n",
       "13021   en    Soft Rock   10755                            The Boxer   \n",
       "13022   en    Soft Rock    5624  Me And Julio Down By The Schoolyard   \n",
       "\n",
       "            artista                                             letras  \n",
       "0      Stratovarius  Again I see you standing there watching me.You...  \n",
       "1      Stratovarius  I feel the wind in my hair.And it's whispering...  \n",
       "2      Stratovarius  The times are changing so fast.I wonder how lo...  \n",
       "3      Stratovarius  Worthless without time.We follow how it flies ...  \n",
       "4      Stratovarius  All through the night he is lying awake.Wond'r...  \n",
       "...             ...                                                ...  \n",
       "13018    Paul Simon  The Mississippi delta.Was shining like a natio...  \n",
       "13019    Paul Simon  It turns out to be.A great thing for me.I don'...  \n",
       "13020    Paul Simon  Well I'm accustomed to a smooth ride.Or maybe ...  \n",
       "13021    Paul Simon  I am just a poor boy though my story's seldom ...  \n",
       "13022    Paul Simon  The mama pajama rolled out of bed.And she ran ...  \n",
       "\n",
       "[13023 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor(object): \n",
    "    \n",
    "    def __init__(self, language='en', remove_stopwords=True, remove_punctuation=True, \n",
    "                 convert_numbers = False, remove_numbers = True, simplification=True, \n",
    "                 simplification_type='lemmatization', lower_case = True): \n",
    "        self.language = language\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.convert_numbers = convert_numbers\n",
    "        self.remove_numbers = remove_numbers\n",
    "        self.simplification = simplification\n",
    "        self.simplification_type = simplification_type \n",
    "        self.lower_case = lower_case\n",
    "\n",
    "\n",
    "    # Complete function to standardize the text\n",
    "    def text_cleaner(self, text): \n",
    "        new_text = ''\n",
    "        stopwords = None \n",
    "\n",
    "        if self.language == 'en':\n",
    "            stopwords = stopwords_en \n",
    "        else:\n",
    "            stopwords = stopwords_pt\n",
    "\n",
    "        if self.lower_case == True: \n",
    "            text = text.lower()\n",
    "\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        \n",
    "        if self.remove_stopwords == True:\n",
    "            new_tokens = []\n",
    "            for token in tokens: \n",
    "                if token in stopwords:\n",
    "                    continue \n",
    "                else: \n",
    "                    new_tokens.append(token)\n",
    "            tokens = new_tokens \n",
    "\n",
    "        if self.remove_punctuation == True: \n",
    "            new_tokens = []\n",
    "            for token in tokens: \n",
    "                if token in string.punctuation:\n",
    "                    continue \n",
    "                else: \n",
    "                    new_tokens.append(token)\n",
    "            tokens = new_tokens \n",
    "        \n",
    "        if self.remove_numbers == True:\n",
    "            new_tokens = []\n",
    "            for token in tokens: \n",
    "                if token.isnumeric():\n",
    "                    continue\n",
    "                new_tokens.append(token)\n",
    "            tokens = new_tokens \n",
    "        \n",
    "        if self.convert_numbers == True: \n",
    "            new_tokens = []\n",
    "            for token in tokens: \n",
    "                if token.isnumeric():\n",
    "                    new_tokens.append(\"0\"*len(token))\n",
    "                else: \n",
    "                    new_tokens.append(token)\n",
    "            tokens = new_tokens \n",
    "\n",
    "        if self.simplification == True: \n",
    "            new_tokens = []\n",
    "            if self.language == 'en': \n",
    "                if self.simplification_type  == 'lemmatization':\n",
    "                    for token in tokens: \n",
    "                        new_tokens.append(lemmatizer.lemmatize(token))\n",
    "                elif self.simplification_type  == 'stemming':\n",
    "                    for token in tokens: \n",
    "                        new_tokens.append(stemmer_en.stem(token))\n",
    "                else: \n",
    "                    raise ValueError('Unsuported language. Please, use language = {\"pt\",\"en\"}.')\n",
    "            elif self.language == 'pt':\n",
    "                for token in tokens: \n",
    "                        new_tokens.append(stemmer_en.stem(token))\n",
    "            else: \n",
    "                raise ValueError('Unsuported language. Please, use language = {\"pt\",\"en\"}.')\n",
    "            tokens = new_tokens\n",
    "\n",
    "        return ' '.join(tokens).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):  \n",
    "    # re.sub(replace_expression, replace_string, target)\n",
    "    new_text = re.sub(r\"\\.|,|;|:|-|’|!|\\?|´|`|^|'\", \" \", text)\n",
    "    new_text = new_text.strip()\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just a simple tokenizer\n",
    "def tokenizer(text):\n",
    "    text = text.lower()\n",
    "    lista_alfanumerica = []\n",
    "\n",
    "    for token in nltk.word_tokenize(text):\n",
    "        if token in string.punctuation:\n",
    "            continue \n",
    "        if token in stopwords_en: \n",
    "            continue\n",
    "        if token.isnumeric():\n",
    "            token = \"0\"*len(token)\n",
    "\n",
    "        lista_alfanumerica.append(token)\n",
    "    return lista_alfanumerica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_preprocessor = TextPreprocessor()\n",
    "\n",
    "texts = data['letras']\n",
    "\n",
    "texts = texts.apply(text_preprocessor.text_cleaner)\n",
    "texts = texts.apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model,window_size,dim_size,max_epochs,texts):\n",
    "    language_model = None\n",
    "    sg = 0\n",
    "    alpha = 0.025\n",
    "    min_alpha = 0.0001\n",
    "    min_count = 5\n",
    "    \n",
    "    list_tokens_texts = texts.apply(tokenizer)\n",
    "    \n",
    "    output = 'custom_rock_{}_{}_{}_{}d.txt'.format(model,max_epochs,window_size,dim_size)\n",
    "    \n",
    "    print('Bulding '+output+' model')\n",
    "    \n",
    "    if model == 'cbow' : \n",
    "        language_model = gensim.models.Word2Vec(list_tokens_texts,sg=sg, min_count=min_count, window=window_size, size=dim_size,\n",
    "                   workers= 4, iter=max_epochs, alpha = alpha, min_alpha = min_alpha)\n",
    "    elif model == 'sg': \n",
    "        language_model = gensim.models.Word2Vec(list_tokens_texts,sg=sg, min_count=min_count, window=window_size, size=dim_size,\n",
    "                   workers= 4, iter=max_epochs, alpha = alpha, min_alpha = min_alpha)\n",
    "        sg = 1\n",
    "    elif model == 'fasttext': \n",
    "        language_model = gensim.models.FastText(list_tokens_texts,sg=sg, min_count=min_count, window=window_size, size=dim_size,\n",
    "                   workers= 4, iter=max_epochs, alpha = alpha, min_alpha = min_alpha)\n",
    "        sg = 1\n",
    "    else: \n",
    "        raise ValueError('Unsuported language model. Please, use language model = {\"cbow\",\"sg\",\"fasttext\"}.')\n",
    "    print()\n",
    "    \n",
    "    #language_model.save(fname=output)\n",
    "    language_model.wv.save_word2vec_format(fname=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Params\n",
    "models = ['sg','cbow','fasttext'] \n",
    "window_sizes = [5, 8, 10]\n",
    "num_dimensions = [25, 50, 100, 300]\n",
    "num_max_epochs = [1, 3, 5, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulding custom_rock_sg_1_5_25d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_3_5_25d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_5_5_25d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_50_5_25d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_1_5_50d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_3_5_50d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_5_5_50d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_50_5_50d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_1_5_100d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_3_5_100d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_5_5_100d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_50_5_100d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_1_5_300d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_3_5_300d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_5_5_300d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_50_5_300d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_1_8_25d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_3_8_25d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_5_8_25d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_50_8_25d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_1_8_50d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_3_8_50d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_5_8_50d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_50_8_50d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_1_8_100d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_3_8_100d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_5_8_100d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_50_8_100d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_1_8_300d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_3_8_300d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_5_8_300d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_50_8_300d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_1_10_25d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_3_10_25d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_5_10_25d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_50_10_25d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_1_10_50d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_3_10_50d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_5_10_50d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_50_10_50d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_1_10_100d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_3_10_100d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_5_10_100d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_50_10_100d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_1_10_300d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_3_10_300d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_5_10_300d.txt model\n",
      "\n",
      "Bulding custom_rock_sg_50_10_300d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_1_5_25d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_3_5_25d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_5_5_25d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_50_5_25d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_1_5_50d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_3_5_50d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_5_5_50d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_50_5_50d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_1_5_100d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_3_5_100d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_5_5_100d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_50_5_100d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_1_5_300d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_3_5_300d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_5_5_300d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_50_5_300d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_1_8_25d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_3_8_25d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_5_8_25d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_50_8_25d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_1_8_50d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_3_8_50d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_5_8_50d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_50_8_50d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_1_8_100d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_3_8_100d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_5_8_100d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_50_8_100d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_1_8_300d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_3_8_300d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_5_8_300d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_50_8_300d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_1_10_25d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_3_10_25d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_5_10_25d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_50_10_25d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_1_10_50d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_3_10_50d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_5_10_50d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_50_10_50d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_1_10_100d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_3_10_100d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_5_10_100d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_50_10_100d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_1_10_300d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_3_10_300d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_5_10_300d.txt model\n",
      "\n",
      "Bulding custom_rock_cbow_50_10_300d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_1_5_25d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_3_5_25d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_5_5_25d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_50_5_25d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_1_5_50d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_3_5_50d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_5_5_50d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_50_5_50d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_1_5_100d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_3_5_100d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_5_5_100d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_50_5_100d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_1_5_300d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_3_5_300d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_5_5_300d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_50_5_300d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_1_8_25d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_3_8_25d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_5_8_25d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_50_8_25d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_1_8_50d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_3_8_50d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_5_8_50d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_50_8_50d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_1_8_100d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_3_8_100d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_5_8_100d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_50_8_100d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_1_8_300d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_3_8_300d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_5_8_300d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_50_8_300d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_1_10_25d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_3_10_25d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_5_10_25d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_50_10_25d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_1_10_50d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_3_10_50d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_5_10_50d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_50_10_50d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_1_10_100d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_3_10_100d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_5_10_100d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_50_10_100d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_1_10_300d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_3_10_300d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_5_10_300d.txt model\n",
      "\n",
      "Bulding custom_rock_fasttext_50_10_300d.txt model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    for window_size in window_sizes:\n",
    "        for dim_size in num_dimensions:\n",
    "            for max_epochs in num_max_epochs:\n",
    "                 build_model(model,window_size,dim_size,max_epochs,texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miscelaneuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = list(sentences.progress_apply(str.split).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of vocab in our custom word embedding\n",
    "\n",
    "len(model.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find words with similar meaning to 'iphone'\n",
    "model.wv.most_similar('iphone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model.wv.save_word2vec_format('custom_glove_100d.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
